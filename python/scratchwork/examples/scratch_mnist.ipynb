{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import cluster, pairwise_distances, normalized_mutual_info_score, silhouette_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from FlagRep0 import FlagRep, truncate_svd, chordal_distance\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)                   \n",
    "    torch.manual_seed(seed)                \n",
    "    torch.cuda.manual_seed(seed)           \n",
    "    torch.cuda.manual_seed_all(seed)       \n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "\n",
    "def make_Bs(fl_type):\n",
    "    Bs = [np.arange(fl_type[0])]\n",
    "    for i in range(1,len(fl_type)):\n",
    "        Bs.append(np.arange(fl_type[i-1],fl_type[i]))\n",
    "    return Bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Input layer to hidden layer 1\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # Hidden layer 1 to hidden layer 2\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # Hidden layer 2 to hidden layer 3\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        # Hidden layer 3 to output layer (10 classes)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # No activation on the output (for logits)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Set up hyperparameters\n",
    "input_size = 28 * 28  # Flattened image size\n",
    "hidden_size = 128     # Same size for all hidden layers\n",
    "output_size = 10      # 10 output classes (digits 0-9)\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_531252/3880814060.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model0.load_state_dict(torch.load('../models/mnist_model0.pth'))\n",
      "/tmp/ipykernel_531252/3880814060.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1.load_state_dict(torch.load('../models/mnist_model1.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model0 = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "model0.load_state_dict(torch.load('../models/mnist_model0.pth'))\n",
    "\n",
    "model1 = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "model1.load_state_dict(torch.load('../models/mnist_model1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fc2.weight.detach().cpu().numpy()\n",
    "np.linalg.matrix_rank(model1.fc2.weight.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flags3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
