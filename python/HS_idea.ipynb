{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "\n",
    "from FlagRep import FlagRep, chordal_distance\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def make_Bs(fl_type):\n",
    "    Bs = [np.arange(fl_type[0])]\n",
    "    for i in range(1,len(fl_type)):\n",
    "        Bs.append(np.arange(fl_type[i-1],fl_type[i]))\n",
    "    return Bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Train and evaluate kNN classifier with precomputed distances\n",
    "def evaluate_knn_with_distances(distance_matrix_train, distance_matrix_test, y_train, y_test, k_values):\n",
    "    accuracies = []\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric='precomputed')\n",
    "        \n",
    "        # Fit the model using the training distance matrix and labels\n",
    "        knn.fit(distance_matrix_train, y_train)\n",
    "        \n",
    "        # Predict using the test distance matrix\n",
    "        y_pred = knn.predict(distance_matrix_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"k={k}, Accuracy: {accuracy:.4f}\")\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "#Train and evaluate kNN classifier with precomputed distances\n",
    "def evaluate_knn(data_train, data_test, y_train, y_test, k_values):\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "        # Fit the model using the training distance matrix and labels\n",
    "        knn.fit(data_train, y_train)\n",
    "        \n",
    "        # Predict using the test distance matrix\n",
    "        y_pred = knn.predict(data_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"k={k}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def extract_patches_of_class(data, labels, patch_size, target_class):\n",
    "    \"\"\"\n",
    "    Extract non-overlapping patches where all pixels in the patch are of the target class.\n",
    "\n",
    "    :param data: The hyperspectral image data \n",
    "    :param labels: The ground truth labels \n",
    "    :param patch_size: Size of the patch (e.g., 7 for 7x7 patches).\n",
    "    :param target_class: The class for which patches should be extracted.\n",
    "    :return: A list of patches (each patch is of size patch_size x patch_size x num_bands).\n",
    "    \"\"\"\n",
    "    half_patch = patch_size // 2\n",
    "    patches = []\n",
    "    patch_labels = []\n",
    "\n",
    "    # Iterate through the image in steps of patch_size to avoid overlap\n",
    "    for i in range(half_patch, data.shape[0] - half_patch, patch_size):\n",
    "        for j in range(half_patch, data.shape[1] - half_patch, patch_size):\n",
    "            # Extract the patch from both the data and the labels\n",
    "            label_patch = labels[i - half_patch:i + half_patch + 1, j - half_patch:j + half_patch + 1]\n",
    "            \n",
    "            # Check if all pixels in the label patch are of the target class\n",
    "            if np.all(label_patch == target_class):\n",
    "                # Extract the corresponding data patch\n",
    "                patch = data[i - half_patch:i + half_patch + 1, j - half_patch:j + half_patch + 1, :]\n",
    "                patches.append(patch)\n",
    "                patch_labels.append(target_class)\n",
    "\n",
    "    return np.array(patches), np.array(patch_labels)\n",
    "\n",
    "\n",
    "def extract_data_mat(data, labels, patch_size, class_ids, feats = 'pixels'):\n",
    "    # extract patches\n",
    "    mod_data = []\n",
    "    mod_labels = []\n",
    "    for target_class in class_ids:#[1,2,3,4,5,6,7,8,9,10,11,12,13]: #[8,10,11,14]:#[8,10,11,14]:#:\n",
    "        patches, patch_labels = extract_patches_of_class(data, labels, patch_size, target_class)\n",
    "        if len(patches) > 0:\n",
    "            flat_patches = []\n",
    "            for patch in patches:\n",
    "                # Your 3D array of size 11x11x200\n",
    "                array_3d = patch  # Example array\n",
    "\n",
    "                center_x, center_y = patch_size//2, patch_size//2\n",
    "\n",
    "                # Create a list of all (x, y) coordinates and compute their Manhattan distances from the center\n",
    "                coords = [(x, y) for x in range(patch_size) for y in range(patch_size)]\n",
    "                distances = [(x, y, max(abs(x - center_x), abs(y - center_y))) for x, y in coords]\n",
    "\n",
    "                # Sort coordinates by distance\n",
    "                sorted_coords = sorted(distances, key=lambda item: item[2])\n",
    "\n",
    "                # Create the 2D array by unwrapping the 3D array based on sorted coordinates\n",
    "                flat_patch = np.array([array_3d[x, y, :] for x, y, _ in sorted_coords])\n",
    "                if feats == 'bands':\n",
    "                    flat_patches.append(flat_patch)\n",
    "                elif feats == 'pixels':\n",
    "                    flat_patches.append(flat_patch.T)\n",
    "\n",
    "                # Create a hierarchy vector containing the Chebyshev distances in the same sorted order\n",
    "                hierarchy_vector = np.array([distance for _, _, distance in sorted_coords])\n",
    "\n",
    "                # Find the indices where the hierarchy vector changes value\n",
    "                change_indices = np.where(np.diff(hierarchy_vector) != 0)[0] + 1  # Add 1 because diff reduces length by 1\n",
    "\n",
    "            change_indices = np.hstack([change_indices,np.array(len(hierarchy_vector))])\n",
    "            mod_labels +=[target_class]*len(patches)\n",
    "            \n",
    "            mod_data += flat_patches\n",
    "\n",
    "        if feats == 'pixels':\n",
    "            Aset = [np.arange(i) for i in change_indices]\n",
    "        elif feats == 'bands':\n",
    "            Aset = [np.arange(10),np.arange(30),np.arange(100)]\n",
    "        print(f\"Extracted {len(patches)} patches where all pixels are of class {class_names[target_class]}. Each patch has shape {patch_size}.\")\n",
    "    return mod_data, mod_labels, Aset\n",
    "\n",
    "\n",
    "def baseline_visuals(mod_data, mod_labels, class_names):\n",
    "    #visualizations\n",
    "\n",
    "    pca = PCA(n_components = 2)\n",
    "    vis_data_pca = pca.fit_transform(np.vstack([m.flatten() for m in mod_data]))\n",
    "\n",
    "    plt.figure()\n",
    "    unique_labels = np.unique(mod_labels)\n",
    "    for l in unique_labels:\n",
    "        idx = np.where(mod_labels == l)\n",
    "        plt.scatter(vis_data_pca[idx,0], vis_data_pca[idx,1], alpha=.5, label = class_names[l])\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    tsne = TSNE(n_components = 2, init = \"random\", random_state = 10)\n",
    "    vis_data_tsne = tsne.fit_transform(np.vstack([m.flatten() for m in mod_data]))\n",
    "\n",
    "    plt.figure()\n",
    "    unique_labels = np.unique(mod_labels)\n",
    "    for l in unique_labels:\n",
    "        idx = np.where(mod_labels == l)\n",
    "        plt.scatter(vis_data_tsne[idx,0], vis_data_tsne[idx,1], alpha=.5, label = class_names[l])\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel('t-SNE1')\n",
    "    plt.ylabel('t-SNE2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = sio.loadmat('../data/Salinas/Salinas.mat')['salinas']  \n",
    "labels = sio.loadmat('../data/Salinas/Salinas_gt.mat')['salinas_gt']  \n",
    "class_names = {\n",
    "    1: \"Brocoli_green_weeds_1\",\n",
    "    2: \"Brocoli_green_weeds_2\",\n",
    "    3: \"Fallow\",\n",
    "    4: \"Fallow_rough_plow\",\n",
    "    5: \"Fallow_smooth\",\n",
    "    6: \"Stubble\",\n",
    "    7: \"Celery\",\n",
    "    8: \"Grapes_untrained\",\n",
    "    9: \"Soil_vinyard_develop\",\n",
    "    10: \"Corn_senesced_green_weeds\",\n",
    "    11: \"Lettuce_romaine_4wk\",\n",
    "    12: \"Lettuce_romaine_5wk\",\n",
    "    13: \"Lettuce_romaine_6wk\",\n",
    "    14: \"Lettuce_romaine_7wk\",\n",
    "    15: \"Vinyard_untrained\",\n",
    "    16: \"Vinyard_vertical_trellis\"\n",
    "        }\n",
    "class_ids = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "patch_size = 9 #works\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "cutoff = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols, n_bands = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = data.reshape((n_rows*n_cols, n_bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # data = scipy.io.loadmat('../data/KSC/KSC.mat')['KSC']\n",
    "    # labels = scipy.io.loadmat('../data/KSC/KSC_gt.mat')['KSC_gt']\n",
    "    # class_names = {1: 'Scrub',\n",
    "    #             2: 'Willow swamp',\n",
    "    #             3: 'Cabbage palm hammock',\n",
    "    #             4: 'Cabbage palm/oak hammock',\n",
    "    #             5: 'Slash pine',\n",
    "    #             6: 'Oak/broad leaf hammock',\n",
    "    #             7: 'Hardwood swamp',\n",
    "    #             8: 'Graminoid marsh',\n",
    "    #             9: 'Spartina marsh',\n",
    "    #             10: 'Cattail marsh',\n",
    "    #             11: 'Salt marsh',\n",
    "    #             12: 'Mudflats',\n",
    "    #             13: 'Water'}\n",
    "    # class_ids = [1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "    # patch_size = 3\n",
    "    # k_values = [1, 2, 3, 4, 5]\n",
    "    # cutoff = .95\n",
    "\n",
    "    # patch_size = 9\n",
    "    # k_values = [1, 2, 3, 4, 5, 6, 7, 9]\n",
    "    # cutoff = .3\n",
    "\n",
    "    methods = ['FlagRep', 'SVD', 'QR', 'Euclidean']\n",
    "\n",
    "  \n",
    "\n",
    "    dist_mats = {}\n",
    "    flag_data = {}\n",
    "    flag_types = {}\n",
    "    \n",
    "    mod_data, mod_labels, Aset = extract_patches(data, labels, patch_size, class_ids, feats = 'pixels')\n",
    "\n",
    "    n,p = mod_data[0].shape\n",
    "    fl_type_easy = [a[-1]+1 for a in Aset]#[i for i in range(np.min([n,p]))]\n",
    "    n_pts = len(mod_data)\n",
    "\n",
    "    for method_name in methods:\n",
    "        print(f'Starting method {method_name}')\n",
    "        # make the flags\n",
    "        flag_data[method_name] = []\n",
    "        flag_types[method_name] = []\n",
    "        for pt in tqdm.tqdm(mod_data):\n",
    "            if method_name == 'FlagRep':\n",
    "                flag_pt, f_type = FlagRep(pt, Aset, eps_rank = cutoff)\n",
    "                flag_types[method_name].append(f_type)\n",
    "                if f_type[-1] < p:\n",
    "                    print(f_type)\n",
    "            elif method_name == 'SVD':\n",
    "                U,S,_ = np.linalg.svd(pt)\n",
    "                # s_prop = np.cumsum(S**2)/np.sum(S**2)\n",
    "                # idx = np.where(s_prop<=cutoff)[0]\n",
    "                # flag_pt = U[:,idx]\n",
    "                # flag_types[method_name].append([len(idx)])\n",
    "                flag_pt = U[:,:fl_type_easy[-1]]\n",
    "                flag_types[method_name].append(fl_type_easy)\n",
    "            elif method_name == 'QR':\n",
    "                Q,_ = np.linalg.qr(pt)\n",
    "                flag_pt = Q\n",
    "                flag_types[method_name].append(fl_type_easy)\n",
    "            elif method_name == 'Euclidean':\n",
    "                flag_pt = flag_pt.flatten()\n",
    "            flag_data[method_name].append(flag_pt)\n",
    "            \n",
    "        #make distance matrices\n",
    "        dist_mats[method_name] = np.zeros((n_pts,n_pts))\n",
    "        for i in tqdm.tqdm(range(n_pts)):\n",
    "            for j in range(i+1,n_pts):\n",
    "                x = flag_data[method_name][i]\n",
    "                y = flag_data[method_name][j]\n",
    "                if method_name == 'Euclidean':\n",
    "                    dist = np.linalg.norm(x-y)\n",
    "                else:\n",
    "                    fl_type_x = flag_types[method_name][i]\n",
    "                    fl_type_y = flag_types[method_name][j]\n",
    "                    Bs_x = make_Bs(fl_type_x)\n",
    "                    Bs_y = make_Bs(fl_type_y)\n",
    "                    dist = chordal_distance(x, y, Bs_x, Bs_y)\n",
    "                dist_mats[method_name][i,j] = dist\n",
    "                dist_mats[method_name][j,i] = dist\n",
    "            \n",
    "    results = pd.DataFrame(columns = ['k','Method Name', 'Accuracy', 'Seed'])\n",
    "\n",
    "    indices = np.arange(len(mod_labels))\n",
    "    mod_labels = np.array(mod_labels)\n",
    "\n",
    "    # fig,ax = plt.subplots(1,3, figsize = (25,5))\n",
    "    # for i, method_name in enumerate(methods[:-1]):\n",
    "    #     tsne = TSNE(n_components=2,metric='precomputed', init = \"random\", random_state = 10)\n",
    "    #     vis_data = tsne.fit_transform(dist_mats[method_name])\n",
    "\n",
    "    #     unique_labels = np.unique(mod_labels)\n",
    "    #     for l in unique_labels:\n",
    "    #         idx = np.where(mod_labels == l)\n",
    "    #         ax[i].scatter(vis_data[idx,0], vis_data[idx,1], alpha=.5, label = class_names[l])\n",
    "    #     ax[i].set_xlabel('t-SNE1')\n",
    "    #     ax[i].set_title(method_name)\n",
    "    # ax[0].set_ylabel('t-SNE2')\n",
    "    # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # fig,ax = plt.subplots(1,3)\n",
    "    # for i, method_name in enumerate(methods[:-1]):\n",
    "    #     ax[i].imshow(dist_mats[method_name], cmap = 'Greys')\n",
    "    #     ax[i].set_title(method_name)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    for s in range(20):\n",
    "\n",
    "        # Step 2: Perform train-test split based on labels using the indices\n",
    "        train_indices, test_indices, _, _ = train_test_split(indices, mod_labels, test_size=0.3, stratify=mod_labels, random_state=s)\n",
    "\n",
    "        # Step 3: Use these indices to retrieve the corresponding data and labels\n",
    "        # (This step assumes `data` is an array of the same length as `labels`)\n",
    "        for method_name in methods:\n",
    "\n",
    "            distance_matrix_train = dist_mats[method_name][train_indices,:][:,train_indices]\n",
    "            distance_matrix_test = dist_mats[method_name][test_indices,:][:,train_indices]\n",
    "            y_train = mod_labels[train_indices]\n",
    "            y_test = mod_labels[test_indices]\n",
    "\n",
    "            # Step 5: Test for different values of k (number of neighbors)\n",
    "\n",
    "            accs = evaluate_knn_with_distances(distance_matrix_train, distance_matrix_test, y_train, y_test, k_values)\n",
    "\n",
    "            for k, acc in zip(k_values, accs):\n",
    "                res = pd.DataFrame(columns = results.columns,\n",
    "                                data = [[k, method_name, acc, s]])\n",
    "                results = pd.concat([results,res])\n",
    "\n",
    "\n",
    "    sns.boxplot(data = results, x = 'k', y = 'Accuracy', hue = 'Method Name')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flags3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
